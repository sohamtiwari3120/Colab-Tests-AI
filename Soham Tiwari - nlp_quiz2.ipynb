{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Soham Tiwari - nlp_quiz2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WKIPkrmmUIuh"},"source":["##  Softmax\n","Write softmax to convert vectors into probability distribution <br>\n","1) All the elements of probability distribution should be positive. <br>\n","2) Sum of all the elements of distribution will be 1. <br>\n","\n","$Softmax(x_i) = \n","\\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}$\n"]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"btXWSnSzUSwL","nbgrader":{"checksum":"28a5e10245b99b8ab2b48da1294931ce","grade":false,"grade_id":"cell-4294a66554d00ee0","locked":false,"schema_version":1,"solution":true},"colab":{}},"source":["import math\n","import numpy as np\n","def softmax(vector):\n","  \"\"\"\n","  Input : \n","      vector: np array of floats\n","  Output:\n","      distribution: np array of floats of same size as that of input converted by using softmax\n","  \"\"\"\n","  # YOUR CODE HERE\n","  vector=vector.reshape(-1,1)\n","#   print(vector)\n","  distribution=[]\n","  sum=np.sum(np.exp(vector))\n","#   print(vector.shape[0])\n","  for i in range(vector.shape[0]):\n","    distribution+=[np.exp(vector[i])/sum]\n","  return np.array(distribution) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"jgSQYlhoUYqm","nbgrader":{"checksum":"8ff6ce9c264971c4fcbae23ee8ee2801","grade":true,"grade_id":"cell-17756755bdef637a","locked":true,"points":2,"schema_version":1,"solution":false},"colab":{"base_uri":"https://localhost:8080/","height":67},"outputId":"88c5bb6c-05ec-425b-edfa-b696afff6cbd","executionInfo":{"status":"ok","timestamp":1561178114875,"user_tz":-330,"elapsed":1252,"user":{"displayName":"Soham Tiwari","photoUrl":"https://lh4.googleusercontent.com/-XiZ5rEdluPQ/AAAAAAAAAAI/AAAAAAAAH24/lvfjFM0g8Uw/s64/photo.jpg","userId":"06949155908663757402"}}},"source":["softmax(np.array([1,2,3]))"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.09003057],\n","       [0.24472847],\n","       [0.66524096]])"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ZxZ2s-atUbGD"},"source":["### Convert to One hot\n","Given a vector containing a probability distribution, convert it to one-hot vector with the max index having 1 and rest of the indices having 0"]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"nXonICNLUtHI","nbgrader":{"checksum":"f5705ac653b727a1382d43c8b0316aad","grade":false,"grade_id":"cell-ba97ad83ad5b99e6","locked":false,"schema_version":1,"solution":true},"colab":{}},"source":["def convert_to_one_hot(p):\n","  \"\"\"\n","  Inputs:\n","    p: numpy array of 1 dimension, probability distribution\n","  Outputs:\n","    oh: one_hot vector corresponding to p\n","  \"\"\"\n","  # YOUR CODE HERE\n","  max=0\n","  p=p.reshape(-1,1)\n","  for i in range(p.shape[0]):\n","    if(p[i]>p[max]):\n","      max=i\n","  oh=[]\n","  for i in range(p.shape[0]):\n","    if(p[i]==p[max]):\n","      oh+=[1]\n","    else:\n","      oh+=[0]\n","  return np.array(oh)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"c2ZuIvAdVNCK","nbgrader":{"checksum":"92856f376c2458b0ef41c939ae27f397","grade":true,"grade_id":"cell-dae6f55da8097488","locked":true,"points":2,"schema_version":1,"solution":false},"colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6c224bd6-82ca-4eb9-b6e4-d1b77c5b4321","executionInfo":{"status":"ok","timestamp":1561178114894,"user_tz":-330,"elapsed":1135,"user":{"displayName":"Soham Tiwari","photoUrl":"https://lh4.googleusercontent.com/-XiZ5rEdluPQ/AAAAAAAAAAI/AAAAAAAAH24/lvfjFM0g8Uw/s64/photo.jpg","userId":"06949155908663757402"}}},"source":["convert_to_one_hot(softmax(np.array([1,2,3])))"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 1])"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4ZXt3L4zVk2l"},"source":["## Complete analogy \n","\n","**Cosine Similarity:**\n","We can find the similarity in terms of  angle between two vectors. Formally, the Cosine Similarity  is  between two vectors  p  and  q  is defined as:\n","\n","$s = \\frac{p‚ãÖq}{||p||||q||} $, where s‚àà[‚àí1,1]<br>\n","Implement the function"]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"5o7TWJYDVk48","nbgrader":{"checksum":"057c75e1bb9747b6827147dd16add597","grade":false,"grade_id":"cell-c710883418fe64f9","locked":false,"schema_version":1,"solution":true},"colab":{}},"source":["import math\n","import numpy as np\n","def cosine_similarity(v1,v2):\n","    \"\"\"\n","    Input:\n","        v1: numpy array \n","        v2: numpy array\n","        \n","    Output:\n","        v: single floating point value\n","        \n","        v = cosine similarity between v1 and v2 = (v1 dot v2)/{||v1||*||v2||}\n","    \"\"\"\n","    # YOUR CODE HERE\n","    v=v1.dot(v2)\n","    v/=np.linalg.norm(v1)*np.linalg.norm(v2)\n","    return v"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"IBRXJTiVVk7F","nbgrader":{"checksum":"ca10ad33f541472c8e6e4ba85c99f401","grade":true,"grade_id":"cell-1ddefb3eb9ea742f","locked":true,"points":3,"schema_version":1,"solution":false},"colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"5184916e-1821-4fca-c6ed-2a43828a9806","executionInfo":{"status":"ok","timestamp":1561178114906,"user_tz":-330,"elapsed":1024,"user":{"displayName":"Soham Tiwari","photoUrl":"https://lh4.googleusercontent.com/-XiZ5rEdluPQ/AAAAAAAAAAI/AAAAAAAAH24/lvfjFM0g8Uw/s64/photo.jpg","userId":"06949155908663757402"}}},"source":["cosine_similarity(np.array([1,0]),np.array([1,0]))"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ayLS2H-LVk89"},"source":["Consider the words $a, b, c, d$ and their corresponding word vectors $x_a, x_b, x_c, x_d$ such that they have this analogical relationship\n","$a:b :: c:d$ <br>\n","For eg.,<br>\n","Princess: Queen : : Prince : ? <br>\n","Complete the analogy by finding the missing word. <br>\n","To find out missing word \"d\", you need to find the word vector which has maximum cosine similarity with the vector $x_b - x_a + x_c$. The word corresponding to this vector is the word that will complete the analogy. In other words, you need to implment the following function <br>\n","$d = argmax_{x_i \\in \\mathcal{X}} \\frac{(x_b-x_a+x_c)^Tx_i}{||x_b-x_a+x_c||\\cdot ||x_i||}$\n"]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"caAFxm09V2bE","nbgrader":{"checksum":"73bfd294eacef5166359054db16e971d","grade":false,"grade_id":"cell-9e2fdcaab9a983a6","locked":false,"schema_version":1,"solution":true},"colab":{}},"source":["def complete_analogy(a, b, c, word_dict):\n","  \"\"\"\n","  Inputs:\n","    a, b, c: strings, with analogical relationship as described above\n","    word_dict: dictionary, dictionary with keys as words and values as corresponding word vectors\n","  Output:\n","      missing: str, the missing word d\n","  \"\"\"\n","  # YOUR CODE HERE\n","  x_a=np.array(word_dict[a])\n","  x_b=np.array(word_dict[b])\n","  x_c=np.array(word_dict[c])\n","  \n","  words=list(word_dict.keys())\n","  cos_values=[]\n","  x_d=x_c-x_a+x_b\n","  for i in words:\n","    cos_values+=[cosine_similarity(x_d,word_dict[i])]\n","  max=0\n","  for i in range(len(cos_values)):\n","    if(cos_values[i]>cos_values[max]):\n","      max=i\n","#   print(words[max])\n","  return words[max]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"2kwj81EHV3pz","nbgrader":{"checksum":"76ebd769ce21a3f481e4d29a8bdd687e","grade":true,"grade_id":"cell-63c4d958a4192123","locked":true,"points":3,"schema_version":1,"solution":false},"outputId":"d825db23-dff6-4bad-ddae-85232e1ec133","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1561178114917,"user_tz":-330,"elapsed":955,"user":{"displayName":"Soham Tiwari","photoUrl":"https://lh4.googleusercontent.com/-XiZ5rEdluPQ/AAAAAAAAAAI/AAAAAAAAH24/lvfjFM0g8Uw/s64/photo.jpg","userId":"06949155908663757402"}}},"source":["word_dict = {'princess':\t[-1.720603,\t-3.560657],\n","             'queen':\t[-0.722603,\t-1.232549],\n","\t           'girl':\t[-2.789075,\t-3.869762],\n","             'king':\t[-0.370373,\t0.576843],\n","            'prince':\t[-1.693504,\t0.719822],\n","            'toy':\t[2.78,\t-0.71],\n","            'lady':\t[-1.693,\t-0.7192],\n","            'student':\t[-1.693504,\t0.719822]}\n","\n","'''test for complete_analogy'''\n","def test_complete_analogy():\n","  assert (complete_analogy(\"princess\",\"queen\",\"prince\",word_dict))==\"king\"\n","  print(\"Test passed üëç\")\n","test_complete_analogy()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Test passed üëç\n"],"name":"stdout"}]}]}